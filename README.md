
# Pipeline de Dados da B3 na AWS - Tech Challenge FIAP



https://g.co/gemini/share/269056fca3f3 - `Link para p√°gina de apresenta√ß√£o`



## 1. Introdu√ß√£o
Este reposit√≥rio cont√©m a implementa√ß√£o de um pipeline de dados **serverless na AWS**, desenvolvido como parte do Tech Challenge da Fase 2 da P√≥s-gradua√ß√£o em **Machine Learning Engineering da FIAP**.

O projeto consiste em um fluxo de **ETL (Extra√ß√£o, Transforma√ß√£o e Carga)** completo e automatizado, que:
1. Coleta a composi√ß√£o di√°ria do √≠ndice Ibovespa (IBOV) do site da B3
2. Processa e enriquece os dados
3. Armazena em um Data Lake
4. Disponibiliza para an√°lise via SQL

## 2. Arquitetura do Pipeline
Arquitetura **event-driven** com componentes desacoplados para garantir resili√™ncia e manutenibilidade:

[![arq.png](https://i.postimg.cc/pXs0L4Cn/arq.png)](https://postimg.cc/xcbGssW0)

## 3. Requisitos do Projeto e Implementa√ß√£o

### Requisito 1: Scrap de dados do site da B3
‚úÖ **Status:** Atendido  
üîß **Implementa√ß√£o:**  
Fun√ß√£o Lambda (`scrapb3`) em Python 3.10 usando:
- `requests` para conex√£o com API da B3
- Tratamento de pagina√ß√£o
- Pandas para manipula√ß√£o inicial

### Requisito 2: Ingest√£o em S3 em Parquet
‚úÖ **Status:** Atendido  
üîß **Implementa√ß√£o:**  
- Serializa√ß√£o com `pyarrow`
- Formato Parquet + compress√£o Snappy
- Parti√ß√£o di√°ria no estilo Hive: `s3://.../raw/date=2025-07-30/`

### Requisito 3: S3 Trigger ‚Üí Lambda ‚Üí Glue
‚úÖ **Status:** Atendido  
üîß **Implementa√ß√£o:**  
- Gatilho S3 configurado para `s3:ObjectCreated:*`
- Aciona Lambda `orquestrador-glue` ao detectar novo arquivo em `raw/`

### Requisito 4: Lambda para iniciar Glue Job
‚úÖ **Status:** Atendido  
üîß **Implementa√ß√£o:**  
Lambda `orquestrador-glue` em Python:
- Chama API Glue via `boto3.glue_client.start_job_run()`
- Executa purge nos diret√≥rios de destino antes do job

### Requisito 5: Glue Job no modo visual
‚úÖ **Status:** Atendido  
üîß **Implementa√ß√£o:**  
Job `processar-dados-bovespa-visual` no Glue Studio com:

| Transforma√ß√£o          | T√©cnica                          |
|------------------------|----------------------------------|
| Agrupamento num√©rico   | N√≥ "Aggregate" por `type`        |
| Renomear colunas       | N√≥s "Rename Field"               |
| C√°lculo com datas      | Custom Transform (PySpark)       |

**Detalhes das transforma√ß√µes:**  
```python
# C√°lculo de timestamp (Custom Transform)
df = df.withColumn("timestamp_processamento", current_timestamp())
df = df.withColumn("lag_processamento_segundos", 
                  col("timestamp_processamento").cast("long") - col("data_coleta").cast("long"))
```

### Requisito 6: Dados refinados em Parquet particionados
‚úÖ **Status:** Atendido  
üîß **Implementa√ß√£o:**
- Salvo em `s3://.../refined/`
- Particionamento por: `ano`, `mes`, `dia`, `codigo_acao`

### Requisito 7: Cataloga√ß√£o autom√°tica no Glue Catalog
‚úÖ **Status:** Atendido  
üîß **Implementa√ß√£o:** Sinks configurados com:
- "Create/update table in Data Catalog"
- Tabelas criadas: `dados_bovespa_refinados_visual` e `sumarizacao_por_tipo`

### Requisito 8: Dados dispon√≠veis no Athena
‚úÖ **Status:** Atendido  
üîß **Implementa√ß√£o:** Valida√ß√£o via consultas:
```sql
SELECT * FROM dados_bovespa_refinados_visual LIMIT 10;
```

### Requisito 9: Notebook para visualiza√ß√£o (Opcional)
‚úÖ **Status:** Atendido  
üîß **Implementa√ß√£o:** Notebook Athena com:
- Consultas via `boto3`
- Visualiza√ß√µes em ASCII (devido a limita√ß√µes do ambiente)
- Gr√°ficos de Top 10 a√ß√µes e participa√ß√£o por tipo

## 4. Tecnologias Utilizadas

| Categoria            | Tecnologias/AWS Services           |
|----------------------|------------------------------------|
| Computa√ß√£o Serverless| AWS Lambda                         |
| Armazenamento        | Amazon S3                          |
| ETL                  | AWS Glue (Studio + PySpark)        |
| Cataloga√ß√£o          | AWS Glue Data Catalog              |
| Orquestra√ß√£o         | EventBridge + S3 Triggers          |
| An√°lise              | Amazon Athena                      |
| IAM                  | AWS Identity and Access Management |
| Linguagens           | Python 3.10                        |
| Bibliotecas          | Boto3, Pandas, PyArrow             |

## 5. Autor
**Argus Cordeiro Sales Portal**  
Turma MLET5 - FIAP
